[
  {
    "type": "text",
    "content": "My stock portfolio is deep in the red. We\u2019re in the midst of a painful market decline. Almost certainly triggered by the tariffs announced by the Trump administration.",
    "audio": "./output/audio/chunk_000.wav"
  },
  {
    "type": "text",
    "content": "But within that big story lies a smaller, subtler one.",
    "audio": "./output/audio/chunk_001.wav"
  },
  {
    "type": "text",
    "content": "You might have seen how the administration calculated those tariffs: not based on actual foreign tariffs but on trade deficits. Even more oddly, some clues suggest that a large language model like ChatGPT might have been used to come up with the formula. We may never know for sure, but the possibility itself changed my view on LLMs.",
    "audio": "./output/audio/chunk_002.wav"
  },
  {
    "type": "image",
    "path": "./output/images/img_000.jpg"
  },
  {
    "type": "text",
    "content": "LLMs now influence many decisions, from small everyday decisions to, potentially, global economy-wrecking decisions. And I\u2019m not excluded. Just in the past few days, I\u2019ve used LLMs for:",
    "audio": "./output/audio/chunk_003.wav"
  },
  {
    "type": "text",
    "content": "Pricing used bicycle parts I want to sell",
    "audio": "./output/audio/chunk_004.wav"
  },
  {
    "type": "text",
    "content": "Choosing a Bootstrap theme for my website (christophmolnar.com)",
    "audio": "./output/audio/chunk_005.wav"
  },
  {
    "type": "text",
    "content": "Filling in invoicing details",
    "audio": "./output/audio/chunk_006.wav"
  },
  {
    "type": "text",
    "content": "Even when I don\u2019t delegate an entire decision to an LLM, I often rely on the information they generate. At least as one more data point.",
    "audio": "./output/audio/chunk_007.wav"
  },
  {
    "type": "text",
    "content": "So this begs the question: What does the LLM contain in terms of knowledge, values, and biases?",
    "audio": "./output/audio/chunk_008.wav"
  },
  {
    "type": "text",
    "content": "We are just beginning to understand LLMs, which also are an ever-shifting target due to continuous improvements and changes.",
    "audio": "./output/audio/chunk_009.wav"
  },
  {
    "type": "text",
    "content": "Most of the behavior is determined by the training data and procedure. No one \u201ctold\u201d the model how to compute tariffs, for example. Instead, it absorbs patterns through self-supervised learning, human feedback (RLHF), and fine-tuning. For example, RLHF might be the reason you see words like \u201cdelve\u201d more often.",
    "audio": "./output/audio/chunk_010.wav"
  },
  {
    "type": "text",
    "content": "At a meta-level, companies wield control by choosing the data, the RLHF process, and the people involved. That realization hit home when I thought about the possibility of tariffs being set by an LLM.",
    "audio": "./output/audio/chunk_011.wav"
  },
  {
    "type": "text",
    "content": "But maybe I\u2019m overreacting?",
    "audio": "./output/audio/chunk_012.wav"
  },
  {
    "type": "text",
    "content": "After all, Google\u2019s search algorithm already has massive influence over what information we see. Maybe this is just an old problem in new clothes? Think about social media feeds or YouTube recommendation loops. These systems already shape public opinion and behavior at scale.",
    "audio": "./output/audio/chunk_013.wav"
  },
  {
    "type": "text",
    "content": "Still, I think LLMs introduce some new dimensions to this issue. The lack of interpretability is one. While older algorithms were often opaque too, many were at least simpler or more transparent. And LLMs are being used not just for recommendations, but for tasks like summarizing and sorting documents. Tasks that are often happening in the background with little human oversight and which often feed into other decision processes.",
    "audio": "./output/audio/chunk_014.wav"
  },
  {
    "type": "text",
    "content": "A malicious actor could hide instructions in the model\u2019s weights. Through fine-tuning, someone could plant backdoors like outputting insecure code when prompted in certain ways or feeding conspiracy theories to susceptible users based on chat history. Given this power, we need tools to understand what\u2019s going on inside these models. One promising direction ismechanistic interpretability.",
    "audio": "./output/audio/chunk_015.wav"
  },
  {
    "type": "text",
    "content": "Mechanistic Interpretability aims to reverse-engineer LLMs. Researchers have identified neurons and \u201ccircuits\u201d (combinations of neuron activations) related to certain concepts. For example, manipulating certain neurons can make a modelobsessed with the Golden Gate Bridge. Whatever you ask the model, it finds a way to talk about the Golden Gate Bridge. Or there arerecent findingsthat the LLMs \u201cplan ahead\u201d when prompted to create a poem.",
    "audio": "./output/audio/chunk_016.wav"
  },
  {
    "type": "text",
    "content": "Mechanistic interpretability has a lot of difficulties: LLMs are huge, concepts don\u2019t  map neatly to single neurons, and findings are typically not universal across models.",
    "audio": "./output/audio/chunk_017.wav"
  },
  {
    "type": "text",
    "content": "So far, I\u2019ve stayed away from the topic of Mechanistic Interpretability, but now I\u2019m getting interested as it\u2019s becoming clear that LLMs are here to stay. \ud83d\ude09",
    "audio": "./output/audio/chunk_018.wav"
  },
  {
    "type": "text",
    "content": "I\u2019m currently reading \u201cA Practical Review of Mechanistic Interpretability for Transformer-Based Language Models\u201d to get started with MI.",
    "audio": "./output/audio/chunk_019.wav"
  },
  {
    "type": "text",
    "content": "I don\u2019t know yet where this will lead. Maybe more posts, maybe even a book. Let\u2019s see. I let curiosity be my guide.",
    "audio": "./output/audio/chunk_020.wav"
  }
]